{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HUMINTING/callte-detetion-detail/blob/main/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGfdZjn521qQ",
        "outputId": "e8eb7746-052d-4633-8d1d-62425f432450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# 定义网路结构\n",
        "class VGG16(nn.Module):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(3, 32, 5, 1, 2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 32, 5, 1, 2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 5, 1, 2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1024, 64),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.model(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    mymodel =VGG16()\n",
        "    input = torch.ones((64,3,32,32))\n",
        "    output = mymodel(input)\n",
        "    print(output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywlY2F0G3ber",
        "outputId": "956e86bf-45c6-4a26-da10-0cff38d118e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 画出train图线\n",
        "def plot(train_loss):\n",
        "    # sns.set()\n",
        "    sns.set_style(\"dark\")\n",
        "    # sns.despine()\n",
        "\n",
        "    idx_list = [i for i in range(len(train_loss))]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.rcParams[\"font.size\"] = 18\n",
        "    plt.grid(visible=True, which='major', linestyle='-')\n",
        "    plt.grid(visible=True, which='minor', linestyle='--', alpha=0.5)\n",
        "    # 显示小刻度  minorticks_off()不显示\n",
        "    plt.minorticks_on()\n",
        "\n",
        "    plt.plot(idx_list, train_loss, 'o-', color='red', marker='*', linewidth=1, fillstyle='bottom')\n",
        "\n",
        "    plt.title(\"traning loss\")\n",
        "    plt.xlabel(\"train times\")\n",
        "    plt.ylabel(\"train loss\")\n",
        "    plt.legend([\"positive\", \"commend\"])\n",
        "    plt.savefig(\"train_loss2.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "urq71BBz3kLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# Author: zhanghansen\n",
        "# Created Time: 2022年05月25日 星期三 08时49分36秒\n",
        "\n",
        "# coding:utf-8\n",
        "#\n",
        "import os\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "# from utils.plot_util import plot\n",
        "# from network.Mynetwork import VGG16\n",
        "\n",
        "# 定义训练的设备\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 创建一个transform\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 准备数据\n",
        "train_data = torchvision.datasets.CIFAR10(\"/content/drive/MyDrive/estrus_20191230/1/train\", train=True, transform=transform,\n",
        "                                          download=True)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\"/content/drive/MyDrive/estrus_20191230/1/test\", train=False, transform=transform,\n",
        "                                         download=True)\n",
        "\n",
        "test_data_size = len(test_data)\n",
        "# 加载数据\n",
        "train_dataloader = DataLoader(train_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "def train(model,maxepoch=20) :\n",
        "    mynetwork = model\n",
        "    # 定义损失函数\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    # 定义学习率\n",
        "    learning_rate = 0.01\n",
        "    # 优化器\n",
        "    optimizer = torch.optim.SGD(mynetwork.parameters(), learning_rate)\n",
        "\n",
        "    # 设置训练网络的参数\n",
        "    total_train_step = 0\n",
        "    total_test_step = 0\n",
        "    # 训练轮数\n",
        "    epoch = 0\n",
        "    max_epoch = maxepoch\n",
        "    train_loss = []\n",
        "    test_accuaacy = []\n",
        "    state = {'model':mynetwork.state_dict(),\n",
        "             'optimizer':optimizer.state_dict(),\n",
        "             'epoch':epoch\n",
        "             }\n",
        "    model_save_path = '/content/drive/MyDrive/estrus_20191230/save_weight/'\n",
        "    model_load_path = '/content/drive/MyDrive/estrus_20191230/imgnet/'\n",
        "    # 从加载model的路径下获取所有文件(如果是.pth后缀的文件)\n",
        "    model_files = [file for file in os.listdir(model_load_path) if file.endswith('.pth') ]\n",
        "    model_files.sort(key =lambda x :int((x.split('.')[0]).split('_')[1]))\n",
        "    # maxx = int ((model_files[-1].split('.')[0]).split('_')[1])\n",
        "    # 如果大于0 ,就可以加载\n",
        "    if len(model_files) >0 :\n",
        "        path = model_load_path+model_files[-1]\n",
        "        checkpoint = torch.load(path)\n",
        "        mynetwork.load_state_dict(checkpoint['model'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        epoch = int ((model_files[-1].split('.')[0]).split('_')[1])\n",
        "        print('----load model -----')\n",
        "\n",
        "\n",
        "    for i in range(epoch,max_epoch):\n",
        "        print(\"[----------- {} epoch train ------------]\".format(i + 1))\n",
        "        mynetwork.train()\n",
        "        for data in train_dataloader:\n",
        "            imgs, targets = data\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = mynetwork(imgs)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            # 优化器\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_step += 1\n",
        "            if total_train_step % 100 == 0:\n",
        "                print(\"the {} times train and loss : {} \".format(total_train_step, loss.item()))\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        # 保存训练模型\n",
        "        current_train_model_name = \"model_{}.pth\".format(i+1)\n",
        "        torch.save(state,model_save_path+current_train_model_name)\n",
        "\n",
        "        # 测试\n",
        "        mynetwork.eval()\n",
        "        total_test_loss = 0\n",
        "        total_accuracy = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_dataloader:\n",
        "                imgs, targets = data\n",
        "                imgs = imgs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                outputs = mynetwork(imgs)\n",
        "\n",
        "                loss = loss_fn(outputs, targets)\n",
        "                total_test_loss += loss.item()\n",
        "                accuracy = (outputs.argmax(1) == targets).sum()\n",
        "                total_accuracy += accuracy\n",
        "        print(\"total loss in test : {} .\".format(total_test_loss))\n",
        "        print(\"total accuracy in test : {}% \".format(total_accuracy / test_data_size * 100))\n",
        "\n",
        "        total_test_step += 1\n",
        "    plot(train_loss)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR5wawRY3Wfv",
        "outputId": "76f42b65-4b61-4f52-f22c-f54ca30ede9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awMeNZC_7MML",
        "outputId": "160622f4-3924-444e-9f8d-19aa0f2aa1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 搭建神经网络\n",
        "mynetwork = VGG16().to(device)\n",
        "\n",
        "\n",
        "train(mynetwork ,30)\n",
        "print(\"---over---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "4vUfbwIa4QsH",
        "outputId": "7e02f348-d0fd-4bb8-ea25-5e6007279157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-8ff016d3f857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmynetwork\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---over---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-da1729a3c8db>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, maxepoch)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# 从加载model的路径下获取所有文件(如果是.pth后缀的文件)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmodel_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_load_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmodel_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m# maxx = int ((model_files[-1].split('.')[0]).split('_')[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# 如果大于0 ,就可以加载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-da1729a3c8db>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# 从加载model的路径下获取所有文件(如果是.pth后缀的文件)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmodel_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_load_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmodel_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m# maxx = int ((model_files[-1].split('.')[0]).split('_')[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# 如果大于0 ,就可以加载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}