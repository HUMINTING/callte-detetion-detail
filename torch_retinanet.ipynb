{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HUMINTING/callte-detetion-detail/blob/main/torch_retinanet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN95jWP0Lky8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NapaU9ZvMxVs",
        "outputId": "351ccaac-9358-4d67-977b-6e01a85b945a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt00FYBWLqjK",
        "outputId": "87b26be5-94aa-4e7b-81b0-92e26089972f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-retinanet'...\n",
            "remote: Enumerating objects: 6224, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 6224 (delta 6), reused 9 (delta 2), pack-reused 6205\u001b[K\n",
            "Receiving objects: 100% (6224/6224), 13.48 MiB | 15.98 MiB/s, done.\n",
            "Resolving deltas: 100% (4207/4207), done.\n"
          ]
        }
      ],
      "source": [
        " !git clone https://github.com/fizyr/keras-retinanet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwSHn32MJN4A",
        "outputId": "9e259ec9-bebd-402c-e73f-9005e9de3626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        " !pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40lbOJoqMUqY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import retinanet_resnet50_fpn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6BAS6GMYeb",
        "outputId": "3b40493a-4f28-4432-807f-fd72386f30f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth\" to /root/.cache/torch/hub/checkpoints/retinanet_resnet50_fpn_coco-eeacb38b.pth\n",
            "100%|██████████| 130M/130M [00:01<00:00, 72.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = retinanet_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "GQyvx2B0cVsb",
        "outputId": "4e4c9a33-93a2-4fa6-ad24-9368bb66bccc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-be7bcdb9b2b4>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Model and training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretinanet_resnet50_fpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword_only_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36minner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweights_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_weights_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/retinanet.py\u001b[0m in \u001b[0;36mretinanet_resnet50_fpn\u001b[0;34m(weights, progress, num_classes, weights_backbone, trainable_backbone_layers, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRetinaNet_ResNet50_FPN_Weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOCO_V1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0moverwrite_eps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_api.py\u001b[0m in \u001b[0;36mget_state_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_zip_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1015\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall_storage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstorage_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m         \u001b[0;31m# swap here if byteswapping is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbyteorderdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models.detection import retinanet_resnet50_fpn\n",
        "from PIL import Image\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import random\n",
        "\n",
        "\n",
        "class VOCDataset(Dataset):\n",
        "    def __init__(self, root, image_set='train', transform=None):\n",
        "        self.root = root\n",
        "        self.image_set = image_set\n",
        "        self.transform = transform\n",
        "\n",
        "        self._image_dir = os.path.join(self.root, \"JPEGImages\")\n",
        "        self._annotation_dir = os.path.join(self.root, \"Annotations\")\n",
        "\n",
        "        image_set_file = os.path.join(self.root, \"ImageSets\", \"Main\", f\"{self.image_set}.txt\")\n",
        "        with open(image_set_file, \"r\") as f:\n",
        "            self.ids = [x.strip() for x in f.readlines()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_id = self.ids[index]\n",
        "        img_path = os.path.join(self._image_dir, f\"{img_id}.jpg\")\n",
        "        annotation_path = os.path.join(self._annotation_dir, f\"{img_id}.xml\")\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        target = self.parse_voc_annotation(annotation_path)\n",
        "\n",
        "        if self.transform:\n",
        "            img, target = self.transform(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def parse_voc_annotation(self, path):\n",
        "        tree = ET.parse(path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        class_to_id = {\"standing_all\": 1, \"standing\": 2}\n",
        "\n",
        "        for obj in root.findall(\"object\"):\n",
        "            bbox = obj.find(\"bndbox\")\n",
        "            bbox = [int(bbox.find(\"xmin\").text), int(bbox.find(\"ymin\").text),\n",
        "                    int(bbox.find(\"xmax\").text), int(bbox.find(\"ymax\").text)]\n",
        "            boxes.append(bbox)\n",
        "            labels.append(class_to_id[obj.find(\"name\").text])\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros(0, dtype=torch.int64)\n",
        "        else:\n",
        "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.tensor(labels)\n",
        "\n",
        "        return {\"boxes\": boxes, \"labels\": labels}\n",
        "\n",
        "\n",
        "class NewTransform:\n",
        "    def __init__(self):\n",
        "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    def __call__(self, img, target):\n",
        "        img, target = self.random_horizontal_flip(img, target)\n",
        "        img = transforms.ToTensor()(img)\n",
        "        img = self.normalize(img)\n",
        "        return img, target\n",
        "\n",
        "    def random_horizontal_flip(self, img, target, prob=0.5):\n",
        "        if random.random() < prob:\n",
        "            img = transforms.functional.hflip(img)\n",
        "            width, _ = img.size\n",
        "            boxes = target[\"boxes\"]\n",
        "\n",
        "            if boxes.nelement() > 0:\n",
        "                boxes[:, [0, 2]] = width - boxes[:, [2, 0]]\n",
        "                target[\"boxes\"] = boxes\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "# Data loading\n",
        "transform = NewTransform()\n",
        "train_dataset = VOCDataset(root=\"/content/drive/MyDrive/new_estrus/yolo/train_voc\", image_set=\"train\", transform=transform)\n",
        "val_dataset = VOCDataset(root=\"/content/drive/MyDrive/new_estrus/yolo/val_voc\", image_set=\"val\", transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
        "\n",
        "# Model and training\n",
        "model = retinanet_resnet50_fpn(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "model.train()\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for images, targets in train_loader:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Save model after each epoch (optional)\n",
        "    torch.save(model.state_dict(), f\"model_epoch_{epoch}.pth\")\n",
        "\n",
        "print(\"Training finished.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEbSDcag5jyV"
      },
      "outputs": [],
      "source": [
        "!mv /content/model_epoch_*.pth /content/drive/MyDrive/mt_detection/20231022/troch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSnlssx_Q8jL",
        "outputId": "ce35ef58-9029-4c38-ac21-6e132791e04b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([], device='cuda:0', dtype=torch.int64) tensor([], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(prediction['labels'], prediction['scores'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c33JuP9A7dFw",
        "outputId": "4292e8ad-6e52-4a4c-f301-de1404065a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annotation file looks good!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# 加载COCO注释文件\n",
        "with open('/content/drive/MyDrive/new_estrus/yolo/train_coco.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 确保基础结构存在\n",
        "assert 'images' in data, \"'images' key missing\"\n",
        "assert 'annotations' in data, \"'annotations' key missing\"\n",
        "assert 'categories' in data, \"'categories' key missing\"\n",
        "\n",
        "# 获取所有图像ID和注释ID\n",
        "image_ids = [img['id'] for img in data['images']]\n",
        "annotation_image_ids = [ann['image_id'] for ann in data['annotations']]\n",
        "\n",
        "# 确保每个注释都有一个对应的图像\n",
        "for ann_image_id in annotation_image_ids:\n",
        "    assert ann_image_id in image_ids, f\"No image found for annotation with image_id {ann_image_id}\"\n",
        "\n",
        "# 对于每个注释, 检查边界框坐标\n",
        "for ann in data['annotations']:\n",
        "    x, y, w, h = ann['bbox']\n",
        "    assert w > 0 and h > 0, f\"Invalid bbox dimensions for annotation id {ann['id']}\"\n",
        "\n",
        "# 检查类别标签\n",
        "category_ids = [cat['id'] for cat in data['categories']]\n",
        "for ann in data['annotations']:\n",
        "    assert ann['category_id'] in category_ids, f\"Invalid category_id {ann['category_id']} for annotation id {ann['id']}\"\n",
        "\n",
        "print(\"Annotation file looks good!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51TeKs1Q5tcR",
        "outputId": "e30d2d29-d92d-4760-fff7-7fa981af6ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of images: 3585\n",
            "Number of images with annotations: 2372\n",
            "Number of images without annotations: 1213\n",
            "Image IDs without annotations: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# 加载COCO标注文件\n",
        "with open('/content/drive/MyDrive/new_estrus/yolo/train_coco.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "image_ids = {image['id'] for image in data['images']}\n",
        "annotation_image_ids = {annotation['image_id'] for annotation in data['annotations']}\n",
        "# 查找没有标注的图像id\n",
        "images_without_annotations = image_ids - annotation_image_ids\n",
        "\n",
        "print(f\"Total number of images: {len(image_ids)}\")\n",
        "print(f\"Number of images with annotations: {len(annotation_image_ids)}\")\n",
        "print(f\"Number of images without annotations: {len(images_without_annotations)}\")\n",
        "\n",
        "if images_without_annotations:\n",
        "    print(\"Image IDs without annotations:\", images_without_annotations)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQus28DZ-cIb",
        "outputId": "2f4a7bd4-872b-434a-a47a-505e4f83eaa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of invalid boxes: 0\n"
          ]
        }
      ],
      "source": [
        "invalid_boxes = []\n",
        "\n",
        "for anno in data['annotations']:\n",
        "    x, y, w, h = anno['bbox']\n",
        "\n",
        "    # 这里我们只检查宽度和高度，但你也可以根据需要添加其他条件。\n",
        "    if w <= 0 or h <= 0:\n",
        "        invalid_boxes.append(anno)\n",
        "\n",
        "print(f\"Number of invalid boxes: {len(invalid_boxes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-CTdQsf-gKv",
        "outputId": "eea0b812-2217-475d-c34c-7f1f5bd541c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of boxes outside image bounds: 2\n"
          ]
        }
      ],
      "source": [
        "image_id_to_size = {img['id']: (img['width'], img['height']) for img in data['images']}\n",
        "\n",
        "for anno in data['annotations']:\n",
        "    x, y, w, h = anno['bbox']\n",
        "    img_width, img_height = image_id_to_size[anno['image_id']]\n",
        "\n",
        "    if x + w > img_width or y + h > img_height:\n",
        "        invalid_boxes.append(anno)\n",
        "\n",
        "print(f\"Number of boxes outside image bounds: {len(invalid_boxes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH4wxoUt-0WW",
        "outputId": "14c0bac3-b075-4062-89de-bdad491803a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 3435, 'image_id': 2930, 'category_id': 2, 'bbox': [351, 463, 907, 618], 'area': 560526, 'iscrowd': 0, 'segmentation': []}\n",
            "{'id': 3805, 'image_id': 3115, 'category_id': 1, 'bbox': [437, 379, 832, 703], 'area': 584896, 'iscrowd': 0, 'segmentation': []}\n"
          ]
        }
      ],
      "source": [
        "for box in invalid_boxes:\n",
        "    print(box)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL1ftXmM_Aif",
        "outputId": "e29d9284-5250-41b8-9834-a3f30dfa01b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image ID 2930 size: (1920, 1080)\n",
            "Image ID 3115 size: (1920, 1080)\n"
          ]
        }
      ],
      "source": [
        "print(\"Image ID 2930 size:\", image_id_to_size[2930])\n",
        "print(\"Image ID 3115 size:\", image_id_to_size[3115])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpuCZV3V_bfq",
        "outputId": "a3b649da-5a3f-4061-ab9c-b5c784066a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid boxes have been removed!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# 读取原始标注数据\n",
        "with open('/content/drive/MyDrive/new_estrus/yolo/train_coco.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 找到并删除相关的边界框\n",
        "invalid_box_ids = [3435, 3805]  # 根据您提供的信息，这是两个无效框的ID\n",
        "data['annotations'] = [anno for anno in data['annotations'] if anno['id'] not in invalid_box_ids]\n",
        "\n",
        "# 将修改后的数据保存回JSON文件\n",
        "with open('/content/drive/MyDrive/new_estrus/yolo/train_coco_cleaned.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "print(\"Invalid boxes have been removed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "vw54Up61UHzl",
        "outputId": "2fd9fc7a-f054-4d26-b146-3af9006c6a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Epoch 1/20 - Training Loss: 1.71320715170458, Validation Loss: 1.0617863897130722\n",
            "Epoch 2/20 - Training Loss: 1.0010982219729982, Validation Loss: 1.0264439443042244\n",
            "Epoch 3/20 - Training Loss: 0.9209008522593163, Validation Loss: 0.8930781634408049\n",
            "Epoch 4/20 - Training Loss: 0.8456973681366085, Validation Loss: 0.8793603602658389\n",
            "Epoch 5/20 - Training Loss: 0.8113670080548383, Validation Loss: 0.8373520876147733\n",
            "Epoch 6/20 - Training Loss: 0.7950046650985273, Validation Loss: 0.804946017922355\n",
            "Epoch 7/20 - Training Loss: 0.7690598073492776, Validation Loss: 0.842446814687056\n",
            "Epoch 8/20 - Training Loss: 0.7562176276220137, Validation Loss: 0.8885866161750164\n",
            "Epoch 9/20 - Training Loss: 0.7261001016364874, Validation Loss: 0.7643885531987892\n",
            "Epoch 10/20 - Training Loss: 0.7229013037400138, Validation Loss: 0.9879852938795618\n",
            "Epoch 11/20 - Training Loss: 0.7362359914961737, Validation Loss: 0.7559076537238434\n",
            "Epoch 12/20 - Training Loss: 0.6912074137474102, Validation Loss: 0.9956172222501158\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-53aa40dab575>\u001b[0m in \u001b[0;36m<cell line: 214>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs} - Training Loss: {train_loss}, Validation Loss: {val_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-53aa40dab575>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/retinanet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# get the features from the backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/backbone_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import retinanet_resnet50_fpn\n",
        "\n",
        "# 设置设备\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 类别数\n",
        "num_classes = 3  # 2 classes + background\n",
        "\n",
        "# 加载模型\n",
        "\n",
        "# 1. 不使用预训练权重加载模型\n",
        "model = retinanet_resnet50_fpn(pretrained=False, num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# 2. 加载预训练权重并移除分类头的权重\n",
        "pretrained_weights = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True).state_dict()\n",
        "pretrained_weights = {k: v for k, v in pretrained_weights.items() if not k.startswith(\"head.classifier\")}\n",
        "# 移除与分类相关的权重\n",
        "keys_to_remove = [\"head.classification_head.cls_logits.weight\", \"head.classification_head.cls_logits.bias\"]\n",
        "for key in keys_to_remove:\n",
        "    if key in pretrained_weights:\n",
        "        del pretrained_weights[key]\n",
        "\n",
        "# 3. 使用修改后的权重初始化模型\n",
        "model.load_state_dict(pretrained_weights, strict=False)\n",
        "\n",
        "\n",
        "# 数据加载\n",
        "from torchvision.datasets import CocoDetection\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    #transforms.Resize((640, 640)),  # 这将调整图像的大小为800x800，你可以根据需要修改这个尺寸\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 训练数据\n",
        "train_data = CocoDetection(root='/content/drive/MyDrive/new_estrus/yolo/train_coco',\n",
        "                           annFile='/content/drive/MyDrive/new_estrus/yolo/train_coco.json',\n",
        "                           transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# 验证数据\n",
        "val_data = CocoDetection(root='/content/drive/MyDrive/new_estrus/yolo/val_coco',\n",
        "                         annFile='/content/drive/MyDrive/new_estrus/yolo/val_coco.json',\n",
        "                         transform=transform)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, annotations = zip(*batch)\n",
        "\n",
        "    targets = []\n",
        "    for idx, anno in enumerate(annotations):\n",
        "        target = {}\n",
        "\n",
        "        if not anno:\n",
        "            target['boxes'] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target['labels'] = torch.zeros((0,), dtype=torch.int64)\n",
        "        else:\n",
        "            boxes = []\n",
        "            labels = []\n",
        "            for item in anno:\n",
        "                x, y, w, h = item['bbox']\n",
        "\n",
        "                # Ensure positive width and height\n",
        "                if w < 0:\n",
        "                    x = x + w\n",
        "                    w = -w\n",
        "                if h < 0:\n",
        "                    y = y + h\n",
        "                    h = -h\n",
        "\n",
        "                # Convert to [x1, y1, x2, y2] format\n",
        "                x1 = x\n",
        "                y1 = y\n",
        "                x2 = x + w\n",
        "                y2 = y + h\n",
        "\n",
        "                # Clip the bounding box coordinates\n",
        "              # Clip the bounding box coordinates based on the original image size\n",
        "                x1 = min(max(x1, 0), 1919.9)\n",
        "                y1 = min(max(y1, 0), 1079.9)\n",
        "                x2 = min(max(x2, 0), 1919.9)\n",
        "                y2 = min(max(y2, 0), 1079.9)\n",
        "\n",
        "\n",
        "                # Exclude invalid boxes\n",
        "                if (x2 - x1) > 0 and (y2 - y1) > 0:\n",
        "                    boxes.append([x1, y1, x2, y2])\n",
        "                    labels.append(item['category_id'])\n",
        "                else:\n",
        "                    print(f\"Excluding invalid box: {[x1, y1, x2, y2]} at index {idx}\")\n",
        "            target['boxes'] = torch.FloatTensor(boxes).reshape(-1, 4)  # Ensure the shape is [N, 4]\n",
        "            target['labels'] = torch.LongTensor(labels)\n",
        "\n",
        "\n",
        "        targets.append(target)\n",
        "\n",
        "    return list(images), targets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# 优化器和损失\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# 训练和验证函数\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "        images = [image.to(device) for image in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "\n",
        "        # 梯度裁剪\n",
        "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += losses.item()\n",
        "\n",
        "        # 打印每个批次的损失\n",
        "        #print(f\"Batch {batch_idx+1}/{len(data_loader)} - Loss: {losses.item()}\")\n",
        "\n",
        "        # 打印损失字典的每个组件\n",
        "        #for loss_name, loss_value in loss_dict.items():\n",
        "            #print(f\"    {loss_name}: {loss_value.item()}\")\n",
        "\n",
        "        # 检查损失是否为nan\n",
        "        if torch.isnan(losses):\n",
        "            print(\"NAN loss detected!\")\n",
        "            for idx, img in enumerate(images):\n",
        "                # 这里只是为了说明，您可能需要一个更合适的方法来保存或显示图像\n",
        "                torchvision.utils.save_image(img, f\"nan_image_{batch_idx}_{idx}.png\")\n",
        "            # 打印此批次的标注\n",
        "            print(targets)\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\"\"\"def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    criterion = torchvision.models.detection._utils.RetinaNetLossComputation(\n",
        "        num_classes=num_classes\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            # Get model predictions\n",
        "            predictions = model(images)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss_dict = criterion(predictions, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            total_loss += losses.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            # 直接获取模型的损失\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            total_loss += losses.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\"\"\"\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.train()  # 注意这里，我们仍然使用训练模式\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():  # 禁止梯度计算\n",
        "        for images, targets in data_loader:\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            total_loss += losses.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "# 主训练循环\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(model, optimizer, train_loader, device)\n",
        "    val_loss = evaluate(model, val_loader, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
        "\n",
        "# 保存模型\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/mt_detection/20231022/troch/retinanet_epoch20.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载模型\n",
        "model_path = '/content/drive/MyDrive/mt_detection/20231022/troch/retinanet_epoch10.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 定义阈值\n",
        "confidence_threshold = 0.5\n",
        "\n",
        "TP = 0\n",
        "TN = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "        images = [image.to(device) for image in images]\n",
        "\n",
        "        # 获取模型预测\n",
        "        predictions = model(images)\n",
        "\n",
        "        for i, prediction in enumerate(predictions):\n",
        "            true_labels = targets[i]['labels'].cpu().numpy()\n",
        "\n",
        "            # 检查图像中是否有标签为 'standing_all' 或 'standing'\n",
        "            #has_positive_label = any(label in [1, 2] for label in true_labels)\n",
        "            has_both_labels = all(label in true_labels for label in [1, 2])\n",
        "\n",
        "            # 预测的 boxes 和 labels\n",
        "            pred_boxes = prediction['boxes'].cpu().numpy()\n",
        "            pred_labels = prediction['labels'].cpu().numpy()\n",
        "            pred_scores = prediction['scores'].cpu().numpy()\n",
        "\n",
        "            # 根据 confidence_threshold 进行筛选\n",
        "            selected_preds = pred_scores > confidence_threshold\n",
        "            filtered_pred_labels = pred_labels[selected_preds]\n",
        "\n",
        "            # 检查是否有预测为 'standing_all' 或 'standing' 的标签\n",
        "\n",
        "            #has_positive_prediction = any(label in [1, 2] for label in filtered_pred_labels)\n",
        "            has_both_predictions = all(label in filtered_pred_labels for label in [1, 2])\n",
        "\n",
        "            # 计算 TP, TN, FP, FN\n",
        "            if has_both_labels and has_both_predictions:\n",
        "                TP += 1\n",
        "            elif not has_both_labels and not has_both_predictions:\n",
        "                TN += 1\n",
        "            elif not has_both_labels and has_both_predictions:\n",
        "                FP += 1\n",
        "            elif has_both_labels and not has_both_predictions:\n",
        "                FN += 1\n",
        "\n",
        "print(f\"True Positives: {TP}\")\n",
        "print(f\"True Negatives: {TN}\")\n",
        "print(f\"False Positives: {FP}\")\n",
        "print(f\"False Negatives: {FN}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRfhFmPLg7xf",
        "outputId": "05edb284-9a23-4a4c-d35e-e2e4cb35e3dc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positives: 425\n",
            "True Negatives: 304\n",
            "False Positives: 1\n",
            "False Negatives: 168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9_09SiwzgL7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb943ed-7113-4b2a-a90b-a4fcef238ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 - TP: 438\n",
            "Class 1 - TN: 304\n",
            "Class 1 - FP: 0\n",
            "Class 1 - FN: 156\n",
            "\n",
            "Class 2 - TP: 472\n",
            "Class 2 - TN: 304\n",
            "Class 2 - FP: 1\n",
            "Class 2 - FN: 121\n",
            "\n",
            "Class 1 - Precision: 1.0\n",
            "Class 1 - Recall: 0.7373737373737373\n",
            "\n",
            "Class 2 - Precision: 0.9978858350951374\n",
            "Class 2 - Recall: 0.7959527824620574\n"
          ]
        }
      ],
      "source": [
        "# 加载模型\n",
        "model_path = '/content/drive/MyDrive/mt_detection/20231022/troch/retinanet_epoch10.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 定义阈值\n",
        "confidence_threshold = 0.5\n",
        "\n",
        "# 初始化统计量\n",
        "TP_class_1 = 0\n",
        "TN_class_1 = 0\n",
        "FP_class_1 = 0\n",
        "FN_class_1 = 0\n",
        "\n",
        "TP_class_2 = 0\n",
        "TN_class_2 = 0\n",
        "FP_class_2 = 0\n",
        "FN_class_2 = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "        images = [image.to(device) for image in images]\n",
        "\n",
        "        # 获取模型预测\n",
        "        predictions = model(images)\n",
        "\n",
        "        for i, prediction in enumerate(predictions):\n",
        "            true_labels = targets[i]['labels'].cpu().numpy()\n",
        "\n",
        "            # 预测的 boxes 和 labels\n",
        "            pred_boxes = prediction['boxes'].cpu().numpy()\n",
        "            pred_labels = prediction['labels'].cpu().numpy()\n",
        "            pred_scores = prediction['scores'].cpu().numpy()\n",
        "\n",
        "            # 根据 confidence_threshold 进行筛选\n",
        "            selected_preds = pred_scores > confidence_threshold\n",
        "            filtered_pred_labels = pred_labels[selected_preds]\n",
        "\n",
        "            # 类别1的评估\n",
        "            is_true_positive_1 = 1 in true_labels and 1 in filtered_pred_labels\n",
        "            is_true_negative_1 = 1 not in true_labels and 1 not in filtered_pred_labels\n",
        "            is_false_positive_1 = 1 not in true_labels and 1 in filtered_pred_labels\n",
        "            is_false_negative_1 = 1 in true_labels and 1 not in filtered_pred_labels\n",
        "\n",
        "            TP_class_1 += is_true_positive_1\n",
        "            TN_class_1 += is_true_negative_1\n",
        "            FP_class_1 += is_false_positive_1\n",
        "            FN_class_1 += is_false_negative_1\n",
        "\n",
        "            # 类别2的评估\n",
        "            is_true_positive_2 = 2 in true_labels and 2 in filtered_pred_labels\n",
        "            is_true_negative_2 = 2 not in true_labels and 2 not in filtered_pred_labels\n",
        "            is_false_positive_2 = 2 not in true_labels and 2 in filtered_pred_labels\n",
        "            is_false_negative_2 = 2 in true_labels and 2 not in filtered_pred_labels\n",
        "\n",
        "            TP_class_2 += is_true_positive_2\n",
        "            TN_class_2 += is_true_negative_2\n",
        "            FP_class_2 += is_false_positive_2\n",
        "            FN_class_2 += is_false_negative_2\n",
        "\n",
        "print(\"Class 1 - TP:\", TP_class_1)\n",
        "print(\"Class 1 - TN:\", TN_class_1)\n",
        "print(\"Class 1 - FP:\", FP_class_1)\n",
        "print(\"Class 1 - FN:\", FN_class_1)\n",
        "\n",
        "print(\"\\nClass 2 - TP:\", TP_class_2)\n",
        "print(\"Class 2 - TN:\", TN_class_2)\n",
        "print(\"Class 2 - FP:\", FP_class_2)\n",
        "print(\"Class 2 - FN:\", FN_class_2)\n",
        "\n",
        "precision_class_1 = TP_class_1 / (TP_class_1 + FP_class_1)\n",
        "recall_class_1 = TP_class_1 / (TP_class_1 + FN_class_1)\n",
        "\n",
        "precision_class_2 = TP_class_2 / (TP_class_2 + FP_class_2)\n",
        "recall_class_2 = TP_class_2 / (TP_class_2 + FN_class_2)\n",
        "\n",
        "print(\"\\nClass 1 - Precision:\", precision_class_1)\n",
        "print(\"Class 1 - Recall:\", recall_class_1)\n",
        "\n",
        "print(\"\\nClass 2 - Precision:\", precision_class_2)\n",
        "print(\"Class 2 - Recall:\", recall_class_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "id": "s4zmR-noGT-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 定义训练和验证损失\n",
        "epochs = list(range(1, 13))\n",
        "training_loss = [1.71320715170458, 1.0010982219729982, 0.9209008522593163, 0.8456973681366085, 0.8113670080548383, 0.7950046650985273, 0.7690598073492776, 0.7562176276220137, 0.7261001016364874, 0.7229013037400138, 0.7362359914961737, 0.6912074137474102]\n",
        "validation_loss = [1.0617863897130722, 1.0264439443042244, 0.8930781634408049, 0.8793603602658389, 0.8373520876147733, 0.804946017922355, 0.842446814687056, 0.8885866161750164, 0.7643885531987892, 0.9879852938795618, 0.7559076537238434, 0.9956172222501158]\n",
        "\n",
        "# 创建图表\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, training_loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, validation_loss, 'b', label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "j9Si2WHYGVFC",
        "outputId": "657ec3f6-bf8e-4f7c-f825-ee984fe40d96"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyM3SxvjG/QgmH0mKGV4IbYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}