{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HUMINTING/callte-detetion-detail/blob/main/train_resnet%26vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ8T4rFcUGKl"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models\n",
        "#from effnetv2 import effnetv2_s\n",
        "from torch.autograd import Variable\n",
        " \n",
        "# 设置超参数\n",
        " \n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 100\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        " \n",
        "# 数据预处理\n",
        " \n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    # transforms.RandomVerticalFlip(),\n",
        "    # transforms.RandomCrop(50),\n",
        "    # transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        " \n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "# 读取数据\n",
        "dataset_train = datasets.ImageFolder('/content/drive/MyDrive/estrus_20191230/1/train', transform)\n",
        "print(dataset_train.imgs)\n",
        "# 对应文件夹的label\n",
        "print(dataset_train.class_to_idx)\n",
        "dataset_test = datasets.ImageFolder('/content/drive/MyDrive/estrus_20191230/1/valid', transform_test)\n",
        "# 对应文件夹的label\n",
        "print(dataset_test.class_to_idx)\n",
        " \n",
        "# 导入数据\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "modellr = 1e-4\n",
        " \n",
        "# 实例化模型并且移动到GPU\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# model = effnetv2_s()\n",
        "# num_ftrs = model.classifier.in_features\n",
        "# model.classifier = nn.Linear(num_ftrs, 2)\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)\n",
        "model.to(DEVICE)\n",
        "# 选择简单暴力的Adam优化器，学习率调低\n",
        "optimizer = optim.Adam(model.parameters(), lr=modellr)\n",
        " \n",
        " \n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    modellrnew = modellr * (0.1 ** (epoch // 50))\n",
        "    print(\"lr:\", modellrnew)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = modellrnew\n",
        " \n",
        " \n",
        "# 定义训练过程\n",
        " \n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    sum_loss = 0\n",
        "    total_num = len(train_loader.dataset)\n",
        "    print(total_num, len(train_loader))\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data).to(device), Variable(target).to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print_loss = loss.data.item()\n",
        "        sum_loss += print_loss\n",
        "        if (batch_idx + 1) % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "                       100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
        "    ave_loss = sum_loss / len(train_loader)\n",
        "    print('epoch:{},loss:{}'.format(epoch, ave_loss))\n",
        " \n",
        "\n",
        "def val(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total_num = len(test_loader.dataset)\n",
        "    print(total_num, len(test_loader))\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = Variable(data).to(device), Variable(target).to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            _, pred = torch.max(output.data, 1)\n",
        "            correct += torch.sum(pred == target)\n",
        "            print_loss = loss.data.item()\n",
        "            test_loss += print_loss\n",
        "        correct = correct.data.item()\n",
        "        acc = correct / total_num\n",
        "        avgloss = test_loss / len(test_loader)\n",
        "        print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            avgloss, correct, len(test_loader.dataset), 100 * acc))\n",
        " \n",
        "\n",
        " \n",
        "# 训练\n",
        " \n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
        "    val(model, DEVICE, test_loader)\n",
        "torch.save(model, 'model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9GK2ULKUziU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install redis==2.10.6"
      ],
      "metadata": {
        "id": "HRkglIXOxsDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJay9B8r7Riu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models\n",
        "#from effnetv2 import effnetv2_s\n",
        "from torch.autograd import Variable\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 设置超参数\n",
        " \n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        " \n",
        "# 数据预处理\n",
        " \n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    # transforms.RandomVerticalFlip(),\n",
        "    # transforms.RandomCrop(50),\n",
        "    # transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        " \n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "# 读取数据\n",
        "dataset_train = datasets.ImageFolder('/content/drive/MyDrive/data/1/train', transform)\n",
        "print(dataset_train.imgs)\n",
        "# 对应文件夹的label\n",
        "print(dataset_train.class_to_idx)\n",
        "dataset_test = datasets.ImageFolder('/content/drive/MyDrive/data/1/valid', transform_test)\n",
        "# 对应文件夹的label\n",
        "print(dataset_test.class_to_idx)\n",
        " \n",
        "# 导入数据\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "modellr = 1e-4\n",
        " \n",
        "# 实例化模型并且移动到GPU\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# model = effnetv2_s()\n",
        "# num_ftrs = model.classifier.in_features\n",
        "# model.classifier = nn.Linear(num_ftrs, 2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = torchvision.models.Vgg16(pretrained=True)\n",
        "model.classifier = classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 12),\n",
        "        )\n",
        "model.to(DEVICE)\n",
        "# 选择简单暴力的Adam优化器，学习率调低\n",
        "optimizer = optim.Adam(model.parameters(), lr=modellr)\n",
        " \n",
        " \n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    modellrnew = modellr * (0.1 ** (epoch // 50))\n",
        "    print(\"lr:\", modellrnew)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = modellrnew\n",
        " \n",
        " \n",
        "# 定义训练过程\n",
        "train_losses = []\n",
        "train_acces = []\n",
        "# 用数组保存每一轮迭代中，在测试数据上测试的损失值和精确度，也是为了通过画图展示出来。\n",
        "eval_losses = []\n",
        "eval_acces = []\n",
        "\n",
        " \n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    sum_loss = 0\n",
        "    correct = 0\n",
        "    total_num = len(train_loader.dataset)\n",
        "    print(total_num, len(train_loader))\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data).to(device), Variable(target).to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print_loss = loss.data.item()\n",
        "        sum_loss += print_loss\n",
        "        _, pred = torch.max(output.data, 1)\n",
        "        correct += torch.sum(pred == target)\n",
        "        correct = correct.data.item()\n",
        "        train_acc = correct / total_num\n",
        "        if (batch_idx + 1) % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "                       100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
        "    ave_loss = sum_loss / len(train_loader)\n",
        "    train_losses.append(ave_loss)\n",
        "    train_acces.append(train_acc)\n",
        "    print('epoch:{},loss:{}'.format(epoch, ave_loss))\n",
        " \n",
        "\n",
        "def val(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total_num = len(test_loader.dataset)\n",
        "    print(total_num, len(test_loader))\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = Variable(data).to(device), Variable(target).to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            _, pred = torch.max(output.data, 1)\n",
        "            correct += torch.sum(pred == target)\n",
        "            print_loss = loss.data.item()\n",
        "            test_loss += print_loss\n",
        "        correct = correct.data.item()\n",
        "        acc = correct / total_num\n",
        "        avgloss = test_loss / len(test_loader)\n",
        "        eval_losses.append(avgloss)\n",
        "        eval_acces.append(acc)\n",
        "        print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            avgloss, correct, len(test_loader.dataset), 100 * acc))\n",
        " \n",
        "\n",
        " \n",
        "# 训练\n",
        " \n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
        "    val(model, DEVICE, test_loader)\n",
        "    #plt.plot(np.arange(len(train_losses)), train_losses,label=\"train loss\")\n",
        "\n",
        "    #plt.plot(np.arange(len(train_acces)), train_acces, label=\"train acc\")\n",
        "\n",
        "    plt.plot(np.arange(len(eval_losses)), eval_losses, label=\"valid loss\")\n",
        "\n",
        "    plt.plot(np.arange(len(eval_acces)), eval_acces, label=\"valid acc\")\n",
        "    plt.legend() #显示图例\n",
        "    plt.xlabel('epoches')\n",
        "    plt.ylabel(\"epoch\")\n",
        "    plt.title('Model accuracy&loss')\n",
        "    plt.show()\n",
        "\n",
        "torch.save(model, 'model.pth')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QLXS4Ycy77r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vh8A5wE98ym1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DlXpC4-Jl_hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "classes = ('garbage', 'mt', 'multiple', 'one')\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        " \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = torch.load(\"model.pth\")\n",
        "model.eval()\n",
        "model.to(DEVICE)\n",
        " \n",
        "dataset_test = datasets.ImageFolder('/content/drive/MyDrive/estrus_20191230/2/datatest', transform_test)\n",
        "print(len(dataset_test))\n",
        "# 对应文件夹的label\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "#创建train_acc.csv和var_acc.csv文件，记录loss和accuracy\n",
        "df = pd.DataFrame(columns=['Image Name','predict'])#列名\n",
        "df.to_csv(\"F:/content/drive/MyDrive/estrus_20191230/2/test_predict.csv\",index=False) #路径可以根据需要更改\n",
        "\n",
        "for index in range(len(dataset_test)):\n",
        "    item = dataset_test[index]\n",
        "    img, label = item\n",
        "    img.unsqueeze_(0)\n",
        "    data = Variable(img).to(DEVICE) is \n",
        "    output = model(data)\n",
        "    _, pred = torch.max(output.data, 1)\n",
        "    Image_Name = output\n",
        "    predict = pred\n",
        "    list = [Image_Name,predict]\n",
        "#由于DataFrame是Pandas库中的一种数据结构，它类似excel，是一种二维表，所以需要将list以二维列表的形式转化为DataFrame\n",
        "    data = pd.DataFrame([list])\n",
        "    data.to_csv('F:/content/drive/MyDrive/estrus_20191230/2/test_predict.csv',mode='a',header=False,index=False)#mode设为a,就可以向csv文件追加数据了\n",
        "    print('Image Name:{},predict:{}'.format(dataset_test.imgs[index][0], classes[pred.data.item()]))\n",
        "    index += 1\n",
        " \n"
      ],
      "metadata": {
        "id": "mzk6pdAYV2NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coding=utf-8\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "confusion = np.array(([69, 81, 13, 19],\n",
        "    [0, 305, 1, 76],\n",
        "    [0, 127, 164, 103],\n",
        "    [0, 1, 0, 13],\n",
        "                      ))\n",
        "classes=['1','2','3','4']\n",
        "#画出混淆矩阵\n",
        "def confusion_matrix(confMatrix):\n",
        "    # 热度图，后面是指定的颜色块，可设置其他的不同颜色\n",
        "    plt.imshow(confMatrix, cmap=plt.cm.Blues)\n",
        "    # ticks 坐标轴的坐标点\n",
        "    # label 坐标轴标签说明\n",
        "    indices = range(len(confMatrix))\n",
        "    # 第一个是迭代对象，表示坐标的显示顺序，第二个参数是坐标轴显示列表\n",
        "    # plt.xticks(indices, [0, 1, 2])\n",
        "    # plt.yticks(indices, [0, 1, 2])\n",
        "    plt.xticks(indices, classes,rotation=45)\n",
        "    plt.yticks(indices, classes)\n",
        " \n",
        "    plt.colorbar()\n",
        " \n",
        "    plt.xlabel('预测值')\n",
        "    plt.ylabel('真实值')\n",
        "    plt.title('混淆矩阵')\n",
        " \n",
        "    # plt.rcParams两行是用于解决标签不能显示汉字的问题\n",
        "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        " \n",
        "    # 显示数据\n",
        "    for first_index in range(len(confMatrix)):  # 第几行\n",
        "        for second_index in range(len(confMatrix[first_index])):  # 第几列\n",
        "            if first_index==second_index:\n",
        "                plt.text(first_index, second_index, confMatrix[first_index][second_index],va='center',ha='center',color='white')\n",
        "            else:\n",
        "                plt.text(first_index, second_index, confMatrix[first_index][second_index], va='center', ha='center')\n",
        "    # 在matlab里面可以对矩阵直接imagesc(confusion)\n",
        "    # 显示\n",
        "    plt.show()\n",
        " \n",
        " \n",
        "#计算准确率\n",
        "def calculate_all_prediction(confMatrix):\n",
        "    '''\n",
        "    计算总精度,对角线上所有值除以总数\n",
        "    :return:\n",
        "    '''\n",
        "    total_sum=confMatrix.sum()\n",
        "    correct_sum=(np.diag(confMatrix)).sum()\n",
        "    prediction=round(100*float(correct_sum)/float(total_sum),2)\n",
        "    print('准确率:'+str(prediction)+'%')\n",
        " \n",
        "def calculae_lable_prediction(confMatrix):\n",
        "    '''\n",
        "    计算每一个类别的预测精度:该类被预测正确的数除以该类的总数\n",
        "    '''\n",
        "    l=len(confMatrix)\n",
        "    for i in range(l):\n",
        "        label_total_sum = confMatrix.sum(axis=1)[i]\n",
        "        label_correct_sum=confMatrix[i][i]\n",
        "        prediction = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
        "        print('精确率:'+classes[i]+\":\"+str(prediction)+'%')\n",
        " \n",
        "def calculate_label_recall(confMatrix):\n",
        "    l = len(confMatrix)\n",
        "    for i in range(l):\n",
        "        label_total_sum = confMatrix.sum(axis=0)[i]\n",
        "        label_correct_sum = confMatrix[i][i]\n",
        "        prediction = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
        "        print('召回率:'+classes[i] + \":\" + str(prediction) + '%')\n",
        " \n",
        " \n",
        "confusion_matrix(confusion)\n",
        "calculae_lable_prediction(confusion)\n",
        "calculate_label_recall(confusion)"
      ],
      "metadata": {
        "id": "jVjI2_lLmByB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "classes = ('garbage', 'mt', 'multiple', 'one')\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        " \n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = torch.load(\"model.pth\")\n",
        "model.eval()\n",
        "model.to(DEVICE)\n",
        " \n",
        "dataset_test = datasets.ImageFolder('/content/drive/MyDrive/estrus_20191230/1/datatest', transform_test)\n",
        "print(len(dataset_test))\n",
        "# 对应文件夹的label\n",
        "\n",
        "\n",
        "for index in range(len(dataset_test)):\n",
        "    item = dataset_test[index]\n",
        "    img, label = item\n",
        "    img.unsqueeze_(0)\n",
        "    data = Variable(img).to(DEVICE)\n",
        "    output = model(data)\n",
        "    _, pred = torch.max(output.data, 1)\n",
        "  \n",
        "    print('Image Name:{},predict:{}'.format(dataset_test.imgs[index][0], classes[pred.data.item()]))\n",
        "    index += 1"
      ],
      "metadata": {
        "id": "6lRAPS_gmNwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models\n",
        "#from effnetv2 import effnetv2_s\n",
        "from torch.autograd import Variable\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.models import vgg16\n",
        "# 设置超参数\n",
        " \n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 100\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        " \n",
        "# 数据预处理\n",
        " \n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    # transforms.RandomVerticalFlip(),\n",
        "    # transforms.RandomCrop(50),\n",
        "    # transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        " \n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "# 读取数据\n",
        "dataset_train = datasets.ImageFolder('/content/drive/MyDrive/estrus_20191230/1/train', transform)\n",
        "print(dataset_train.imgs)\n",
        "# 对应文件夹的label\n",
        "print(dataset_train.class_to_idx)\n",
        "dataset_test = datasets.ImageFolder('/content/drive/MyDrive/estrus_20191230/1/valid', transform_test)\n",
        "# 对应文件夹的label\n",
        "print(dataset_test.class_to_idx)\n",
        " \n",
        "# 导入数据\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "modellr = 1e-4\n",
        " \n",
        "# 实例化模型并且移动到GPU\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# model = effnetv2_s()\n",
        "# num_ftrs = model.classifier.in_features\n",
        "# model.classifier = nn.Linear(num_ftrs, 2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model_ft = vgg16(pretrained=True)\n",
        "model_ft.classifier = classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 12),\n",
        "        )\n",
        "model_ft.to(DEVICE)\n",
        "# 选择简单暴力的Adam优化器，学习率调低\n",
        "optimizer = optim.Adam(model.parameters(), lr=modellr)\n",
        " \n",
        " \n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    modellrnew = modellr * (0.1 ** (epoch // 50))\n",
        "    print(\"lr:\", modellrnew)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = modellrnew\n",
        " \n",
        " \n",
        "# 定义训练过程\n",
        "train_losses = []\n",
        "train_acces = []\n",
        "# 用数组保存每一轮迭代中，在测试数据上测试的损失值和精确度，也是为了通过画图展示出来。\n",
        "eval_losses = []\n",
        "eval_acces = []\n",
        "\n",
        " \n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    sum_loss = 0\n",
        "    correct = 0\n",
        "    total_num = len(train_loader.dataset)\n",
        "    print(total_num, len(train_loader))\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data).to(device), Variable(target).to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print_loss = loss.data.item()\n",
        "        sum_loss += print_loss\n",
        "        _, pred = torch.max(output.data, 1)\n",
        "        correct += torch.sum(pred == target)\n",
        "        correct = correct.data.item()\n",
        "        train_acc = correct / total_num\n",
        "        if (batch_idx + 1) % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
        "                       100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
        "    ave_loss = sum_loss / len(train_loader)\n",
        "    train_losses.append(ave_loss)\n",
        "    train_acces.append(train_acc)\n",
        "    print('epoch:{},loss:{}'.format(epoch, ave_loss))\n",
        " \n",
        "\n",
        "def val(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total_num = len(test_loader.dataset)\n",
        "    print(total_num, len(test_loader))\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = Variable(data).to(device), Variable(target).to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            _, pred = torch.max(output.data, 1)\n",
        "            correct += torch.sum(pred == target)\n",
        "            print_loss = loss.data.item()\n",
        "            test_loss += print_loss\n",
        "        correct = correct.data.item()\n",
        "        acc = correct / total_num\n",
        "        avgloss = test_loss / len(test_loader)\n",
        "        eval_losses.append(avgloss)\n",
        "        eval_acces.append(acc)\n",
        "        print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            avgloss, correct, len(test_loader.dataset), 100 * acc))\n",
        " \n",
        "\n",
        " \n",
        "# 训练\n",
        " \n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
        "    val(model, DEVICE, test_loader)\n",
        "    plt.plot(np.arange(len(train_losses)), train_losses,label=\"train loss\")\n",
        "\n",
        "    plt.plot(np.arange(len(train_acces)), train_acces, label=\"train acc\")\n",
        "\n",
        "    plt.plot(np.arange(len(eval_losses)), eval_losses, label=\"valid loss\")\n",
        "\n",
        "    plt.plot(np.arange(len(eval_acces)), eval_acces, label=\"valid acc\")\n",
        "    plt.legend() #显示图例\n",
        "    plt.xlabel('epoches')\n",
        "#plt.ylabel(\"epoch\")\n",
        "    plt.title('Model accuracy&loss')\n",
        "    plt.show()\n",
        "\n",
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "pHtCHYGm81F2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOQnyYUR/OrC1+jaTy3MEav",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}